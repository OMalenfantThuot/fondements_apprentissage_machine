{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Devoir 2 pour IFT6390 - Fondements de l'apprentissage machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Par Olivier Malenfant-Thuot\n",
    "Matricule: 1012818"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Linear and non-linear regularized regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.1 L'ensemble des paramètres $\\theta$ du modèle de régression linéaire sont $\\vec{\\text{w}} \\in {\\rm I\\!R^d}$ et $b \\in {\\rm I\\!R}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.2 Le risque empirique pour un training set $D$, évalué à partir de la fonction de perte $L((x,t),f)$ prend la forme\n",
    "\n",
    "\\begin{equation}\n",
    "    \\hat{R}(f,D) = \\sum\\limits_{(x,t) \\in D}(f(x) - t)^2 = \\sum\\limits_{(x,t) \\in D} (\\vec{\\text{w}}^T \\vec{x} + b - t)^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.3 Nous pouvons utiliser le ERM pour minimiser le risque, avec:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial}{\\partial \\vec{\\text{w}}} \\frac{\\partial}{\\partial b}\\sum\\limits_{(x,t) \\in D} (\\vec{\\text{w}}^T \\vec{x} + b - t)^2 = 0.\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.4 Le gradient du risque empirique peu être exprimé par:\n",
    "\n",
    "\\begin{equation}\n",
    "   \\nabla \\hat{R} = \\sum\\limits_{(x,t) \\in D} \n",
    "   \\begin{bmatrix}\n",
    "       \\frac{\\partial}{\\partial w_1} (\\vec{\\text{w}}^T \\vec{x} + b - t)^2\\\\\n",
    "       \\frac{\\partial}{\\partial w_2} (\\vec{\\text{w}}^T \\vec{x} + b - t)^2\\\\\n",
    "       \\vdots \\\\\n",
    "       \\frac{\\partial}{\\partial w_d} (\\vec{\\text{w}}^T \\vec{x} + b - t)^2\\\\\n",
    "       \\frac{\\partial}{\\partial b} (\\vec{\\text{w}}^T \\vec{x} + b - t)^2\n",
    "   \\end{bmatrix} = \\sum\\limits_{(x,t) \\in D}\n",
    "   \\begin{bmatrix}\n",
    "       2w_1(\\vec{\\text{w}}^T \\vec{x} + b - t)\\\\\n",
    "       2w_2(\\vec{\\text{w}}^T \\vec{x} + b - t)\\\\\n",
    "       \\vdots \\\\\n",
    "       2w_d(\\vec{\\text{w}}^T \\vec{x} + b - t)\\\\\n",
    "       2(\\vec{\\text{w}}^T \\vec{x} + b - t)\n",
    "   \\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.5 Le gradient du risque empirique indique dans quelle direction de l'espace des paramètres $\\theta$ il faut se déplacer afin de diminuer la somme des erreurs de tous les points du training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.1 Le gradient du risque empirique régularisé devient\n",
    "\n",
    "\\begin{equation}\n",
    "   \\nabla \\tilde{R} = \\sum\\limits_{(x,t) \\in D}\n",
    "   \\begin{bmatrix}\n",
    "       2w_1(\\vec{\\text{w}}^T \\vec{x} + b - t) + 2\\lambda w_1\\\\\n",
    "       2w_2(\\vec{\\text{w}}^T \\vec{x} + b - t) + 2\\lambda w_2\\\\\n",
    "       \\vdots \\\\\n",
    "       2w_d(\\vec{\\text{w}}^T \\vec{x} + b - t) + 2\\lambda  w_d\\\\\n",
    "       2(\\vec{\\text{w}}^T \\vec{x} + b - t)\n",
    "   \\end{bmatrix}\n",
    "\\end{equation}.\n",
    "\n",
    "Ce nouveau gradient diffère du précédent par un terme $2\\lambda w_i$ pour chaque dimension $i$, mais est le même pour le bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.2 Pseudocode pour le training:\n",
    "\n",
    "Déterminer aléatoirement des valeurs de départ pour w et b.\n",
    "\n",
    "Définir les valeurs des hyperparamètres $\\lambda$ et $\\eta$.\n",
    "\n",
    "Définir un nombre d'itérations maximal pour l'arrêt du calcul\n",
    "\n",
    "Définir une valeur d'arrêt pour le gradient\n",
    "\n",
    "    iteration = 0\n",
    "    Début d'une boucle sur itermax:\n",
    "        Calcul du gradient par la formule du 1.2.1 pour chaque point du dataset\n",
    "        Calcul de la moyenne des gradients\n",
    "        \n",
    "        Update des valeurs de w et b par:\n",
    "        Ajout du produit entre les d premières dimensions du gradient et -eta à w\n",
    "        Ajout du produit entre la dernière dimension du gradient et -eta à b\n",
    "        \n",
    "        Calcul de la norme du gradient\n",
    "        si la norme du gradient est plus petite que la valeur d'arrêt, break la boucle\n",
    "    \n",
    "Les dernières valeurs de w et b sont les valeurs minimisant le risque empirique régularisé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.3 Le risque empirique et son gradient peuvent être exprimé de façon matricielle de la façon suivante\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "    \\hat{R} = \\|w^T X - t^T \\|^2\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    \\nabla \\hat{R} = \\vec{\\nabla} \\cdot (w^T X)\n",
    "\\end{equation}\n",
    "\n",
    "where $\\vec{\\nabla} =  \\begin{bmatrix}\n",
    "\\frac{\\partial}{\\partial w_1} + \\frac{\\partial}{\\partial w_2} + \\ldots + \\frac{\\partial}{\\partial w_d}\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\partial}{\\partial w_1} + \\frac{\\partial}{\\partial w_2} + \\ldots + \\frac{\\partial}{\\partial w_d}\n",
    "\\end{bmatrix}_{N\\times d}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.4 Le gradient est le même qu'au 1.2.3 plus le terme pour de ridge. La solution au problème de minimisation est\n",
    "\n",
    "\\begin{equation}\n",
    "    \\nabla \\hat{R} = \\vec{\\nabla} \\cdot (w^T X + \\lambda \\|w\\|^2) = 0\n",
    "\\end{equation}\n",
    "\n",
    "Quand $\\lambda = 0$, nous retrouvons l'expression pour le gradient sans le ridge term. Quand $N < d$, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Regression with a fixed non-linear pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.1 L'expression complète de $\\tilde{f}(x)$ est\n",
    "\n",
    "\\begin{equation}\n",
    "\\tilde{f}(x) = \\begin{bmatrix}\n",
    "f(x)\\\\\n",
    "f(x^2)\\\\\n",
    "\\vdots\\\\\n",
    "f(x^k)\n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.2 Les paramètres de l'entraînement entrainer sont:\n",
    "\n",
    "w, de dimension k qui représente le poids à donner à chaque valeur x^i dans la régression,\n",
    "\n",
    "b, le bias de dimension 1, qui joue le même rôle que précédemment,\n",
    "\n",
    "k, de dimension 1, un scalaire qui détermine le nombre de dimensions de la transformation pôlynomiale. C'est un hyperparamètre, car le résultat de l'entraînement dépend de sa valeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
